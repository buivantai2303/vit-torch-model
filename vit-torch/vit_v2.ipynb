{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image, ImageDraw\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "VALID_IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp'}\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DATA_DIR = 'data'\n",
    "MODEL_PATH = 'saved_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Exceptions\n",
    "class DatasetConfigError(Exception):\n",
    "    pass\n",
    "\n",
    "class ImageProcessingError(Exception):\n",
    "    pass\n",
    "\n",
    "# Validate image file\n",
    "def validate_image_file(file_path):\n",
    "    file_path = Path(file_path)\n",
    "    return (\n",
    "        file_path.is_file() and \n",
    "        file_path.suffix.lower() in VALID_IMAGE_EXTENSIONS and \n",
    "        not file_path.name.startswith('.')\n",
    "    )\n",
    "\n",
    "# Get image files from directory\n",
    "def get_image_files(directory):\n",
    "    directory_path = Path(directory)\n",
    "    if not directory_path.is_dir():\n",
    "        raise DatasetConfigError(f\"Directory not found: {directory}\")\n",
    "    \n",
    "    image_files = [str(path) for path in directory_path.rglob('*') if validate_image_file(path)]\n",
    "    \n",
    "    if not image_files:\n",
    "        logger.warning(f\"No valid images found in {directory}\")\n",
    "    \n",
    "    print(f\"Found {len(image_files)} valid image files in {directory}.\")\n",
    "    return image_files\n",
    "\n",
    "# Create data transformations\n",
    "def create_data_transformations(input_size=(224, 224)):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    print(\"Data transformations created.\")\n",
    "    return train_transform, val_transform\n",
    "\n",
    "# Load datasets\n",
    "def load_image_datasets(data_dir, train_transform, val_transform):\n",
    "    train_dir = os.path.join(data_dir, 'train')\n",
    "    val_dir = os.path.join(data_dir, 'val')\n",
    "\n",
    "    for directory, name in [(train_dir, 'training'), (val_dir, 'validation')]:\n",
    "        if not os.path.exists(directory):\n",
    "            raise DatasetConfigError(f\"{name.capitalize()} directory not found: {directory}\")\n",
    "\n",
    "    class FilteredImageFolder(datasets.ImageFolder):\n",
    "        def __init__(self, root, transform=None):\n",
    "            valid_classes = [d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))]\n",
    "            super().__init__(root, transform=transform)\n",
    "            self.samples = [s for s in self.samples if self.classes[s[1]] in valid_classes]\n",
    "\n",
    "    train_dataset = FilteredImageFolder(root=train_dir, transform=train_transform)\n",
    "    val_dataset = FilteredImageFolder(root=val_dir, transform=val_transform)\n",
    "\n",
    "    print(f\"Loaded training dataset with {len(train_dataset)} images across {len(train_dataset.classes)} classes.\")\n",
    "    print(f\"Loaded validation dataset with {len(val_dataset)} images across {len(val_dataset.classes)} classes.\")\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "def create_data_loaders(train_dataset, val_dataset, batch_size=32):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(f\"Data loaders created with batch size {batch_size}.\")\n",
    "    return train_loader, val_loader, train_dataset.classes\n",
    "\n",
    "# Train model\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs, device):\n",
    "    model.train()\n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    train_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    return train_losses\n",
    "\n",
    "# Save model\n",
    "def save_model(model, model_path):\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model saved to {model_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and display images with bounding boxes\n",
    "def predict_and_display_images(model, image_paths, val_transform, class_names, device):\n",
    "    predictions = []\n",
    "    font_size = 24  # Kích thước font chữ\n",
    "    font = ImageFont.truetype(\"arial.ttf\", font_size)  # Đường dẫn đến font chữ nếu cần\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        try:\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "            img_tensor = val_transform(img).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                outputs = model(img_tensor)\n",
    "                probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                top_probs, top_classes = torch.topk(probabilities, k=1)\n",
    "\n",
    "            class_name = class_names[top_classes[0][0].item()]\n",
    "            probability = top_probs[0][0].item() * 100\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            width, height = img.size\n",
    "            box_coords = [10, 10, width - 10, height - 10]  # Ví dụ về tọa độ bounding box\n",
    "            draw.rectangle(box_coords, outline=\"red\", width=3)  \n",
    "\n",
    "            # Tạo nền đỏ cho văn bản\n",
    "            text = f\"{class_name}: {probability:.2f}%\"\n",
    "            text_width, text_height = draw.textsize(text, font=font)\n",
    "            draw.rectangle([15, 15, 15 + text_width, 15 + text_height], fill=\"red\")  # Nền đỏ\n",
    "            draw.text((15, 15), text, fill=\"white\", font=font)  # Chữ trắng\n",
    "\n",
    "            predictions.append(img)\n",
    "            print(f\"Predicted result for {image_path}: {class_name} - {probability:.2f}%\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error predicting image {image_path}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Display images\n",
    "    display_image_grid(predictions)\n",
    "\n",
    "def display_image_grid(images, grid_size=(3, 3)):\n",
    "    \"\"\"Display a grid of images.\"\"\"\n",
    "    num_images = len(images)\n",
    "    cols, rows = grid_size\n",
    "    if num_images > cols * rows:\n",
    "        print(\"Warning: Number of images exceeds grid size. Truncating...\")\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for index, img in enumerate(images[:cols * rows]):\n",
    "        plt.subplot(rows, cols, index + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and train model\n",
    "def load_and_train_model():\n",
    "    train_transform, val_transform = create_data_transformations()\n",
    "    train_dataset, val_dataset = load_image_datasets(DATA_DIR, train_transform, val_transform)\n",
    "    train_loader, val_loader, class_names = create_data_loaders(train_dataset, val_dataset)\n",
    "\n",
    "    # Check if the model has been trained before\n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        print(f\"Loading model from {MODEL_PATH}...\")\n",
    "        model = models.resnet18(pretrained=False)\n",
    "        model.fc = nn.Linear(model.fc.in_features, len(class_names))\n",
    "        model.load_state_dict(torch.load(MODEL_PATH))\n",
    "        model = model.to(DEVICE)\n",
    "        print(\"Model loaded successfully.\")\n",
    "    else:\n",
    "        print(\"Training new model...\")\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, len(class_names))\n",
    "        model = model.to(DEVICE)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        num_epochs = 5\n",
    "\n",
    "        train_losses = train_model(model, train_loader, criterion, optimizer, num_epochs, DEVICE)\n",
    "        save_model(model, MODEL_PATH)\n",
    "\n",
    "    return model, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformations created.\n",
      "Loaded training dataset with 32246 images across 9 classes.\n",
      "Loaded validation dataset with 32246 images across 9 classes.\n",
      "Data loaders created with batch size 32.\n",
      "Data transformations created.\n",
      "Loaded training dataset with 32246 images across 9 classes.\n",
      "Loaded validation dataset with 32246 images across 9 classes.\n",
      "Data loaders created with batch size 32.\n",
      "Training new model...\n",
      "Starting training...\n"
     ]
    }
   ],
   "source": [
    "# Bước 1: Tạo biến chuyển đổi dữ liệu\n",
    "train_transform, val_transform = create_data_transformations()\n",
    "\n",
    "# Bước 2: Tải datasets\n",
    "train_dataset, val_dataset = load_image_datasets(DATA_DIR, train_transform, val_transform)\n",
    "\n",
    "# Bước 3: Tạo Data Loaders\n",
    "train_loader, val_loader, class_names = create_data_loaders(train_dataset, val_dataset)\n",
    "\n",
    "# Bước 4: Tải và huấn luyện mô hình\n",
    "model, class_names = load_and_train_model()\n",
    "\n",
    "# Bước 5: Dự đoán và hiển thị hình ảnh\n",
    "test_images_dir = os.path.join(DATA_DIR, 'test')\n",
    "test_images = get_image_files(test_images_dir)\n",
    "predict_and_display_images(model, test_images, val_transform, class_names, DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
