{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformations created.\n",
      "Loaded training dataset with 1843 images across 9 classes.\n",
      "Loaded validation dataset with 1843 images across 9 classes.\n",
      "Data loaders created with batch size 32.\n",
      "Training new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HI\\Downloads\\ai-vit\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HI\\Downloads\\ai-vit\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/5, Loss: 0.4829\n",
      "Epoch 2/5, Loss: 0.2391\n",
      "Epoch 3/5, Loss: 0.2450\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image, ImageDraw\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "VALID_IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp'}\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DATA_DIR = 'data'\n",
    "MODEL_PATH = 'saved_model.pth'\n",
    "\n",
    "# Custom Exceptions\n",
    "class DatasetConfigError(Exception):\n",
    "    pass\n",
    "\n",
    "class ImageProcessingError(Exception):\n",
    "    pass\n",
    "\n",
    "# Validate image file\n",
    "def validate_image_file(file_path):\n",
    "    file_path = Path(file_path)\n",
    "    return (\n",
    "        file_path.is_file() and \n",
    "        file_path.suffix.lower() in VALID_IMAGE_EXTENSIONS and \n",
    "        not file_path.name.startswith('.')\n",
    "    )\n",
    "\n",
    "# Get image files from directory\n",
    "def get_image_files(directory):\n",
    "    directory_path = Path(directory)\n",
    "    if not directory_path.is_dir():\n",
    "        raise DatasetConfigError(f\"Directory not found: {directory}\")\n",
    "    \n",
    "    image_files = [str(path) for path in directory_path.rglob('*') if validate_image_file(path)]\n",
    "    \n",
    "    if not image_files:\n",
    "        logger.warning(f\"No valid images found in {directory}\")\n",
    "    \n",
    "    print(f\"Found {len(image_files)} valid image files in {directory}.\")\n",
    "    return image_files\n",
    "\n",
    "# Create data transformations\n",
    "def create_data_transformations(input_size=(224, 224)):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    print(\"Data transformations created.\")\n",
    "    return train_transform, val_transform\n",
    "\n",
    "# Load datasets\n",
    "def load_image_datasets(data_dir, train_transform, val_transform):\n",
    "    train_dir = os.path.join(data_dir, 'train')\n",
    "    val_dir = os.path.join(data_dir, 'val')\n",
    "\n",
    "    for directory, name in [(train_dir, 'training'), (val_dir, 'validation')]:\n",
    "        if not os.path.exists(directory):\n",
    "            raise DatasetConfigError(f\"{name.capitalize()} directory not found: {directory}\")\n",
    "\n",
    "    class FilteredImageFolder(datasets.ImageFolder):\n",
    "        def __init__(self, root, transform=None):\n",
    "            valid_classes = [d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))]\n",
    "            super().__init__(root, transform=transform)\n",
    "            self.samples = [s for s in self.samples if self.classes[s[1]] in valid_classes]\n",
    "\n",
    "    train_dataset = FilteredImageFolder(root=train_dir, transform=train_transform)\n",
    "    val_dataset = FilteredImageFolder(root=val_dir, transform=val_transform)\n",
    "\n",
    "    print(f\"Loaded training dataset with {len(train_dataset)} images across {len(train_dataset.classes)} classes.\")\n",
    "    print(f\"Loaded validation dataset with {len(val_dataset)} images across {len(val_dataset.classes)} classes.\")\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "# Create data loaders\n",
    "def create_data_loaders(train_dataset, val_dataset, batch_size=32):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(f\"Data loaders created with batch size {batch_size}.\")\n",
    "    return train_loader, val_loader, train_dataset.classes\n",
    "\n",
    "# Train model\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs, device):\n",
    "    model.train()\n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    train_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    return train_losses\n",
    "\n",
    "# Plot training loss\n",
    "def plot_training_loss(losses):\n",
    "    plt.figure()\n",
    "    plt.plot(losses, label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Predict and display images in a grid\n",
    "def predict_and_display_images(model, image_paths, val_transform, class_names, device):\n",
    "    predictions = []\n",
    "    for image_path in image_paths:\n",
    "        try:\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "            img_tensor = val_transform(img).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                outputs = model(img_tensor)\n",
    "                probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                top_probs, top_classes = torch.topk(probabilities, k=3)\n",
    "\n",
    "            prediction_text = \"\"\n",
    "            for i in range(len(top_classes[0])):\n",
    "                class_name = class_names[top_classes[0][i].item()]\n",
    "                probability = top_probs[0][i].item() * 100\n",
    "                prediction_text += f\"{class_name}: {probability:.2f}% \"\n",
    "            \n",
    "            predictions.append((img, prediction_text))\n",
    "            print(f\"Predicted result for {image_path}: {prediction_text}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error predicting image {image_path}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Display a grid of images with predictions\n",
    "    display_image_grid(predictions)\n",
    "\n",
    "def display_image_grid(predictions, grid_size=(3, 3)):\n",
    "    \"\"\"Display a grid of images with predictions.\"\"\"\n",
    "    num_images = len(predictions)\n",
    "    cols, rows = grid_size\n",
    "    if num_images > cols * rows:\n",
    "        print(\"Warning: Number of images exceeds grid size. Truncating...\")\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for index, (img, prediction_text) in enumerate(predictions[:cols * rows]):\n",
    "        plt.subplot(rows, cols, index + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(prediction_text)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    try:\n",
    "        train_transform, val_transform = create_data_transformations()\n",
    "        train_dataset, val_dataset = load_image_datasets(DATA_DIR, train_transform, val_transform)\n",
    "        train_loader, val_loader, class_names = create_data_loaders(train_dataset, val_dataset)\n",
    "\n",
    "        # Check if the model has been trained before\n",
    "        if os.path.exists(MODEL_PATH):\n",
    "            print(f\"Loading model from {MODEL_PATH}...\")\n",
    "            model = models.resnet18(pretrained=False)\n",
    "            model.fc = nn.Linear(model.fc.in_features, len(class_names))\n",
    "            model.load_state_dict(torch.load(MODEL_PATH))\n",
    "            model = model.to(DEVICE)\n",
    "            print(\"Model loaded successfully.\")\n",
    "        else:\n",
    "            print(\"Training new model...\")\n",
    "            model = models.resnet18(pretrained=True)\n",
    "            model.fc = nn.Linear(model.fc.in_features, len(class_names))\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "            num_epochs = 5\n",
    "\n",
    "            train_losses = train_model(model, train_loader, criterion, optimizer, num_epochs, DEVICE)\n",
    "            plot_training_loss(train_losses)\n",
    "\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            print(f\"Model saved to {MODEL_PATH}.\")\n",
    "\n",
    "        test_images_dir = os.path.join(DATA_DIR, 'test')\n",
    "        if os.path.exists(test_images_dir):\n",
    "            test_images = get_image_files(test_images_dir)\n",
    "            predict_and_display_images(model, test_images, val_transform, class_names, DEVICE)\n",
    "        else:\n",
    "            logger.warning(f\"Test directory not found: {test_images_dir}\")\n",
    "\n",
    "    except (DatasetConfigError, ImageProcessingError) as e:\n",
    "        logger.error(f\"Workflow error: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nb